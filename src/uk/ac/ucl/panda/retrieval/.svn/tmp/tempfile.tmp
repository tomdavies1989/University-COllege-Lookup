package uk.ac.ucl.panda.retrieval;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import uk.ac.ucl.panda.applications.evaluation.trec.Judge;
import uk.ac.ucl.panda.applications.evaluation.trec.QualityBenchmark;
import uk.ac.ucl.panda.applications.evaluation.trec.QualityStats;
import uk.ac.ucl.panda.applications.evaluation.trec.TrecJudge;
import uk.ac.ucl.panda.indexing.ExtraInformation;
import uk.ac.ucl.panda.indexing.io.IndexReader;
import uk.ac.ucl.panda.indexing.io.TrecTopicsReader;
import uk.ac.ucl.panda.retrieval.query.QualityQuery;
import uk.ac.ucl.panda.utility.io.FileReader;
import uk.ac.ucl.panda.utility.io.SubmissionReport;
import uk.ac.ucl.panda.utility.parser.QualityQueryParser;
import uk.ac.ucl.panda.utility.parser.SimpleQQParser;
import uk.ac.ucl.panda.utility.structure.TermDocs;
import uk.ac.ucl.panda.utility.structure.TermFreqVector;


public class TrecRetrieval {

        protected String newline = System.getProperty("line.separator");

        protected String fileseparator = System.getProperty("file.separator");

        protected String docDataField ="body";

    public void correlation(String index, String topics, String qrels, String var) throws Exception {


	    int maxResults = 1000;
	    String docNameField = "docname";
	    FileOutputStream evals =new FileOutputStream(new File(var+fileseparator+"correlation"));
	    PrintWriter logger = new PrintWriter(evals,true);

             FileOutputStream results =new FileOutputStream(new File(var+fileseparator+"results"));
            PrintWriter scorelogger = new PrintWriter(results,true);
	    // use trec utilities to read trec topics into quality queries
	    TrecTopicsReader qReader = new TrecTopicsReader();
	    QualityQuery qqs[] = qReader.readQueries(FileReader.openFileReader(topics));

            ////////////
      //       System.out.println("Number of queries: "+qqs.length);
            ///////////
            IndexReader reader = IndexReader.open(index);

            for(int i = 1 ; i < reader.maxDoc()-1 ; i++){
                for(int j = i+1 ; j < reader.maxDoc() ; j++){
                     double temp = correlation(reader, i,j);
                     logger.println(temp);

                }
              //  logger.println();
            }
	    

    }

	
	public void process (String index, String topics, String qrels, String var) throws Exception{
		
		//Searcher searcher = new Searcher(index);
               

	    int maxResults = 1000;
	    String docNameField = "docname";
	    FileOutputStream evals =new FileOutputStream(new File(var+fileseparator+"evals-hard-bm25"));
	    PrintWriter logger = new PrintWriter(evals,true);

             FileOutputStream results =new FileOutputStream(new File(var+fileseparator+"results"));
            PrintWriter scorelogger = new PrintWriter(results,true);
	    // use trec utilities to read trec topics into quality queries
	    TrecTopicsReader qReader = new TrecTopicsReader();
	    QualityQuery qqs[] = qReader.readQueries(FileReader.openFileReader(topics));

            ////////////
      //       System.out.println("Number of queries: "+qqs.length);
            ///////////
            
	    // prepare judge, with trec utilities that read from a QRels file
	    Judge judge = new TrecJudge(FileReader.openFileReader(qrels));

	    // validate topics & judgments match each other
	    judge.validateData(qqs, logger);

	    // set the parsing of quality queries into Lucene queries.
	    QualityQueryParser qqParser = new SimpleQQParser("title", "body");

	    // run the benchmark
	    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, index, docNameField);
	    qrun.setMaxResults(maxResults);
	    SubmissionReport submitLog = null;
	    
	    
	    
	    QualityStats stats[] = qrun.execute(judge, submitLog, logger, scorelogger);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.log("SUMMARY", 2, logger, "  ");
	
		

		
	}
	
	
        public void batch (String index, String topics, String qrels, String var) throws Exception{
		
		//Searcher searcher = new Searcher(index);
               

	    int maxResults = 1000;
	    String docNameField = "docname";
<<<<<<< .mine
	    FileOutputStream evals =new FileOutputStream(new File(var+fileseparator+"evals-hard-bm25"));
=======
	    FileOutputStream evals =new FileOutputStream(new File(var+fileseparator+"Robust_l_u1000_tfidf"));
>>>>>>> .r275
	    PrintWriter logger = new PrintWriter(evals,true);

             FileOutputStream results =new FileOutputStream(new File(var+fileseparator+"results"));
            PrintWriter scorelogger = new PrintWriter(results,true);
	    // use trec utilities to read trec topics into quality queries
	    TrecTopicsReader qReader = new TrecTopicsReader();
	    QualityQuery qqs[] = qReader.readQueries(FileReader.openFileReader(topics));

            ////////////
      //       System.out.println("Number of queries: "+qqs.length);
            ///////////
            
	    // prepare judge, with trec utilities that read from a QRels file
	    Judge judge = new TrecJudge(FileReader.openFileReader(qrels));

	    // validate topics & judgments match each other
	    judge.validateData(qqs, logger);

	    // set the parsing of quality queries into Lucene queries.
	    QualityQueryParser qqParser = new SimpleQQParser("title", "body");

	    // run the benchmark
	    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, index, docNameField);
	    qrun.setMaxResults(maxResults);
	    SubmissionReport submitLog = null;
	    
            
            //batch
             logger.print("MAP"+'\t'+"MRR"+'\t'+"Recall"+'\t'+"1-call"+'\t'+"2-call"+'\t'+"3-call"+'\t'+"4-call"+'\t'+"5-call"+'\t'+"6-call"+'\t'+"7-call"+'\t'+"8-call"+'\t'+"9-call"+'\t'+"10-call"+'\t'+"NDCG@1"+'\t'+"NDCG@5"+'\t'+"NDCG@10"+'\t'+"NDCG@15"+'\t'+"NDCG@20"+"NDCG@35"+'\t'+"NDCG@50"+'\t'+"NDCG@70"+'\t'+"NDCG@100"+'\t'+"NDCG@200"+'\t'+"NDCG@250"+'\t'+"NDCG@400"+'\t'+"NDCG@500"+'\t'+"NDCG@600"+'\t'+"NDCG@700"+'\t'); 
            for(int i =1; i<=70 ;i++){
                logger.print('\t'+"Precision@"+i);
            }
            
            logger.println();
      /**
       * Var adjust
       */

         /*
	    for(double a1=0.0d; a1<=0.0d; a1+=10.0d){
	    
	    QualityStats stats[] = qrun.execute(judge, submitLog, null, scorelogger, a1, 0);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.batch_log(Double.toString(a1) , 2, logger, "  ");
	
           }
	*/
             /**
       * Doc correlation adjust
       */
       
               for(double a2=-10.0d; a2<=10.0d; a2+=0.5d){

	    QualityStats stats[] = qrun.execute(judge, submitLog, null, scorelogger, 0, a2);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.batch_log(Double.toString(a2) , 2, logger, "  ");

           }
	


	}
<<<<<<< .mine

          public void process_var (String index, String topics, String qrels, String var) throws Exception{

		//Searcher searcher = new Searcher(index);


	    int maxResults = 1000;
	    String docNameField = "docname";
	    FileOutputStream evals =new FileOutputStream(new File(var+fileseparator+"test-ScoreCombine"));
	    PrintWriter logger = new PrintWriter(evals,true);

             FileOutputStream results =new FileOutputStream(new File(var+fileseparator+"results"));
            PrintWriter scorelogger = new PrintWriter(results,true);
	    // use trec utilities to read trec topics into quality queries
	    TrecTopicsReader qReader = new TrecTopicsReader();
	    QualityQuery qqs[] = qReader.readQueries(FileReader.openFileReader(topics));

            ////////////
      //       System.out.println("Number of queries: "+qqs.length);
            ///////////

	    // prepare judge, with trec utilities that read from a QRels file
	    Judge judge = new TrecJudge(FileReader.openFileReader(qrels));

	    // validate topics & judgments match each other
	    judge.validateData(qqs, logger);

	    // set the parsing of quality queries into Lucene queries.
	    QualityQueryParser qqParser = new SimpleQQParser("title", "body");

	    // run the benchmark
	    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, index, docNameField);
	    qrun.setMaxResults(maxResults);
	    SubmissionReport submitLog = null;


            //batch
             logger.print("MAP"+'\t'+"MRR"+'\t'+"Recall"+'\t'+"1-call"+'\t'+"2-call"+'\t'+"3-call"+'\t'+"4-call"+'\t'+"5-call"+'\t'+"6-call"+'\t'+"7-call"+'\t'+"8-call"+'\t'+"9-call"+'\t'+"10-call"+'\t'+"NDCG@1"+'\t'+"NDCG@5"+'\t'+"NDCG@10"+'\t'+"NDCG@15"+'\t'+"NDCG@20"+"NDCG@35"+'\t'+"NDCG@50"+'\t'+"NDCG@70"+'\t'+"NDCG@100"+'\t'+"NDCG@200"+'\t'+"NDCG@250"+'\t'+"NDCG@400"+'\t'+"NDCG@500"+'\t'+"NDCG@600"+'\t'+"NDCG@700"+'\t');
            for(int i =1; i<=70 ;i++){
                logger.print('\t'+"Precision@"+i);
            }

            logger.println();
      /**
       * Var adjust
       */


	    for(double a1=1.0d; a1<=1.0d; a1+=1.0d){

	    QualityStats stats[] = qrun.execute_var(judge, submitLog, null, scorelogger, a1, 0);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.batch_log(Double.toString(a1) , 2, logger, "  ");

           }

             /**
       * Doc correlation adjust
       */
       /*
               for(double a2=-2.0d; a2<=1.0d; a2+=0.1d){

	    QualityStats stats[] = qrun.execute(judge, submitLog, null, scorelogger, 0, a2);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.batch_log(Double.toString(a2) , 2, logger, "  ");

           }
	*/


	}

          public void process_plot (String index, String topics, String qrels, String var) throws Exception{

		//Searcher searcher = new Searcher(index);


	    int maxResults = 1000;
	    String docNameField = "docname";
	    FileOutputStream evals =new FileOutputStream(new File(var+fileseparator+"test-plot"));
	    PrintWriter logger = new PrintWriter(evals,true);

        FileOutputStream relScorePair =new FileOutputStream(new File(var+fileseparator+"rel-score-pair"));
	    PrintWriter relScoreLogger = new PrintWriter(relScorePair,true);

             FileOutputStream results =new FileOutputStream(new File(var+fileseparator+"result-plot"));
            PrintWriter scorelogger = new PrintWriter(results,true);
	    // use trec utilities to read trec topics into quality queries
	    TrecTopicsReader qReader = new TrecTopicsReader();
	    QualityQuery qqs[] = qReader.readQueries(FileReader.openFileReader(topics));

            ////////////
      //       System.out.println("Number of queries: "+qqs.length);
            ///////////

	    // prepare judge, with trec utilities that read from a QRels file
	    Judge judge = new TrecJudge(FileReader.openFileReader(qrels));

	    // validate topics & judgments match each other
	    judge.validateData(qqs, logger);

	    // set the parsing of quality queries into Lucene queries.
	    QualityQueryParser qqParser = new SimpleQQParser("title", "body");

	    // run the benchmark
	    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, index, docNameField);
	    qrun.setMaxResults(maxResults);
	    SubmissionReport submitLog = null;


            //batch
             logger.print("MAP"+'\t'+"MRR"+'\t'+"Recall"+'\t'+"1-call"+'\t'+"2-call"+'\t'+"3-call"+'\t'+"4-call"+'\t'+"5-call"+'\t'+"6-call"+'\t'+"7-call"+'\t'+"8-call"+'\t'+"9-call"+'\t'+"10-call"+'\t'+"NDCG@1"+'\t'+"NDCG@5"+'\t'+"NDCG@10"+'\t'+"NDCG@15"+'\t'+"NDCG@20"+"NDCG@35"+'\t'+"NDCG@50"+'\t'+"NDCG@70"+'\t'+"NDCG@100"+'\t'+"NDCG@200"+'\t'+"NDCG@250"+'\t'+"NDCG@400"+'\t'+"NDCG@500"+'\t'+"NDCG@600"+'\t'+"NDCG@700"+'\t');
            for(int i =1; i<=70 ;i++){
                logger.print('\t'+"Precision@"+i);
            }

            logger.println();
      /**
       * Var adjust
       */


	    for(double a1=0.0d; a1<=0.0d; a1+=1.0d){

	    QualityStats stats[] = qrun.execute_plot(judge, submitLog, null, scorelogger, a1, 0, relScoreLogger);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.batch_log(Double.toString(a1) , 2, logger, "  ");

           }

             /**
       * Doc correlation adjust
       */
       /*
               for(double a2=-2.0d; a2<=1.0d; a2+=0.1d){

	    QualityStats stats[] = qrun.execute(judge, submitLog, null, scorelogger, 0, a2);

	    // print an avarage sum of the results
	    QualityStats avg = QualityStats.average(stats);
	    avg.batch_log(Double.toString(a2) , 2, logger, "  ");

           }
	*/


	}

=======

     //Pearson's product-moment coefficient
    private double correlation(IndexReader reader, int a, int b) throws IOException{
        double score= 0;
         TermFreqVector doc_a=reader.getTermFreqVector(a, docDataField);
         ///////////////
        // if( doc_a==null) System.out.println("doc_a is null");
         ///////////////
         TermFreqVector doc_b=reader.getTermFreqVector(b, docDataField);

         //stroe all the term freq in hashmap
         HashMap term_map =new HashMap();
         HashMap map_a =new HashMap();
         String terms[] = doc_a.getTerms();
         int freq[] = doc_a.getTermFrequencies();
         double ave_a = 0;
         for(int i = 0; i < terms.length ; i++){
            map_a.put(terms[i], freq[i]);
            term_map.put(terms[i], terms[i]);
            ave_a +=freq[i];
         }
         ave_a = ave_a / terms.length;

          double ave_b = 0;
         HashMap map_b =new HashMap();
         terms = doc_b.getTerms();
         freq = doc_b.getTermFrequencies();
         for(int i = 0; i < terms.length ; i++){
            map_b.put(terms[i], freq[i]);
            term_map.put(terms[i], terms[i]);
             ave_b +=freq[i];
         }
         ave_b = ave_b / terms.length;
         //compute correlation
         double sum_up = 0;
         double sum_a = 0;
         double sum_b = 0;

        Collection  Cterm=term_map.values();

  for   (Iterator   iterator   =  Cterm.iterator();   iterator.hasNext();)
  {
      int V_a = 0;
      int V_b = 0;
      String term = (String)iterator.next();
      if(map_a.containsKey(term))V_a = (Integer) map_a.get(term);
      if(map_b.containsKey(term))V_b = (Integer) map_b.get(term);
      sum_up += (1.0d* V_a - ave_a)*(1.0d * V_b - ave_b);
      sum_a += (1.0d* V_a - ave_a) * (1.0d* V_a - ave_a);
      sum_b += (1.0d* V_b - ave_b) * (1.0d* V_b - ave_b);

  }
        score = sum_up / (Math.sqrt(sum_a * sum_b));


        return score;
    }

        
>>>>>>> .r275
	
}
